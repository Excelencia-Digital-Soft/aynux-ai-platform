# =============================================================================
# Aynux Docker Compose - Development Environment
# =============================================================================
# Usage:
#   docker compose up -d              # Start all services
#   docker compose up -d --build      # Rebuild and start
#   docker compose logs -f app        # Follow app logs
#   docker compose down               # Stop all services
#   docker compose down -v            # Stop and remove volumes
#
# Profiles:
#   --profile ollama                  # Include Ollama in Docker (CPU mode)
# =============================================================================

name: aynux

services:
  # ---------------------------------------------------------------------------
  # PostgreSQL with pgvector extension
  # Image includes pgvector pre-installed
  # ---------------------------------------------------------------------------
  postgres:
    image: pgvector/pgvector:pg18
    container_name: aynux-postgres
    restart: unless-stopped
    environment:
      POSTGRES_USER: ${DB_USER:-aynux}
      POSTGRES_PASSWORD: ${DB_PASSWORD:-aynux_dev}
      POSTGRES_DB: ${DB_NAME:-aynux}
      # Performance tuning for development
      POSTGRES_INITDB_ARGS: "--encoding=UTF8 --locale=C"
    ports:
      - "${DB_PORT:-5432}:5432"
    volumes:
      - postgres_data:/var/lib/postgresql
      - ./scripts/init-db.sql:/docker-entrypoint-initdb.d/01-init.sql:ro
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${DB_USER:-aynux} -d ${DB_NAME:-aynux}"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 30s
    networks:
      - aynux-network

  # ---------------------------------------------------------------------------
  # Redis for caching and session storage
  # ---------------------------------------------------------------------------
  redis:
    image: redis:7-alpine
    container_name: aynux-redis
    restart: unless-stopped
    command: >
      redis-server
      --appendonly yes
      --maxmemory 256mb
      --maxmemory-policy allkeys-lru
      --save 60 1000
      --requirepass ${REDIS_PASSWORD:-Excelenci@5948}
    ports:
      - "${REDIS_PORT:-6379}:6379"
    volumes:
      - redis_data:/data
    healthcheck:
      test: ["CMD-SHELL", "REDISCLI_AUTH=${REDIS_PASSWORD:-Excelenci@5948} redis-cli ping"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - aynux-network

  # ---------------------------------------------------------------------------
  # Ollama LLM Service (CPU mode - optional profile)
  # NOTE: For Apple Silicon with GPU acceleration, run Ollama natively:
  #   brew install ollama && ollama serve
  # Then use OLLAMA_API_URL=http://host.docker.internal:11434
  # ---------------------------------------------------------------------------
  ollama:
    image: ollama/ollama:latest
    container_name: aynux-ollama
    restart: unless-stopped
    ports:
      - "11434:11434"
    volumes:
      - ollama_data:/root/.ollama
    environment:
      - OLLAMA_HOST=0.0.0.0
    healthcheck:
      test: ["CMD-SHELL", "curl -sf http://localhost:11434/api/version || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 60s
    networks:
      - aynux-network
    profiles:
      - ollama  # Only starts with: docker compose --profile ollama up

  # ---------------------------------------------------------------------------
  # FastAPI Application (Development with hot-reload)
  # ---------------------------------------------------------------------------
  # NOTE: If docker compose build fails with credential errors, build manually:
  #   docker build --target development -t aynux-app:dev .
  # ---------------------------------------------------------------------------
  app:
    image: aynux-app:dev
    pull_policy: never  # Use local image, don't try to pull from registry
    build:
      context: .
      dockerfile: Dockerfile
      target: development
    restart: unless-stopped
    ports:
      - "8080:8080"
    volumes:
      # Mount source code for hot-reload
      - ./app:/app/app:cached
      # Mount tests for development
      - ./tests:/app/tests:cached
      # Don't mount .venv - use container's virtual environment
    environment:
      # Database Configuration
      - DB_HOST=postgres
      - DB_PORT=5432
      - DB_NAME=${DB_NAME:-aynux}
      - DB_USER=${DB_USER:-aynux}
      - DB_PASSWORD=${DB_PASSWORD:-aynux_dev}
      - DB_POOL_SIZE=5
      - DB_MAX_OVERFLOW=10
      - DB_POOL_RECYCLE=3600
      - DB_POOL_TIMEOUT=30
      - DB_ECHO=false
      # Redis Configuration
      - REDIS_HOST=redis
      - REDIS_PORT=6379
      - REDIS_DB=0
      - REDIS_PASSWORD=${REDIS_PASSWORD}
      # Ollama Configuration
      # Default: localhost (for SSH tunnel or native Ollama)
      # For Docker Ollama: http://ollama:11434
      - OLLAMA_API_URL=${OLLAMA_API_URL:-http://localhost:11434}
      - OLLAMA_API_MODEL_SIMPLE=${OLLAMA_API_MODEL_SIMPLE:-deepseek-r1:1.5b}
      - OLLAMA_API_MODEL_COMPLEX=${OLLAMA_API_MODEL_COMPLEX:-deepseek-r1:7b}
      - OLLAMA_API_MODEL_REASONING=${OLLAMA_API_MODEL_REASONING:-deepseek-r1:7b}
      - OLLAMA_API_MODEL_SUMMARY=${OLLAMA_API_MODEL_SUMMARY:-llama3.2:latest}
      - OLLAMA_API_MODEL_EMBEDDING=${OLLAMA_API_MODEL_EMBEDDING:-nomic-embed-text}
      # pgvector Configuration
      - PGVECTOR_SIMILARITY_THRESHOLD=0.7
      # Application Settings
      - ENVIRONMENT=development
      - DEBUG=true
      - TESTING=false
      # API Configuration
      - API_V1_STR=/api/v1
      - PROJECT_NAME=Aynux WhatsApp Bot
      # Chattigo Integration (WhatsApp via ISV)
      - CHATTIGO_ENABLED=${CHATTIGO_ENABLED:-true}
      - CHATTIGO_BASE_URL=${CHATTIGO_BASE_URL:-https://channels.chattigo.com/bsp-cloud-chattigo-isv}
      - CHATTIGO_USERNAME=${CHATTIGO_USERNAME}
      - CHATTIGO_PASSWORD=${CHATTIGO_PASSWORD}
      - CHATTIGO_CHANNEL_ID=${CHATTIGO_CHANNEL_ID:-12676}
      - CHATTIGO_CAMPAIGN_ID=${CHATTIGO_CAMPAIGN_ID}
      - CHATTIGO_BOT_NAME=${CHATTIGO_BOT_NAME:-Aynux}
      # DUX Sync - controlled via .env file only (not host environment)
      # Set DUX_SYNC_ENABLED=true in .env to enable
      # LangSmith (optional - for tracing)
      - LANGSMITH_TRACING_ENABLED=${LANGSMITH_TRACING_ENABLED:-false}
      - LANGSMITH_API_KEY=${LANGSMITH_API_KEY:-}
      - LANGSMITH_PROJECT=${LANGSMITH_PROJECT:-aynux-dev}
      # Skip DB init since we want to control it
      - SKIP_DB_INIT=false
    env_file:
      - path: .env
        required: false
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    networks:
      - aynux-network

  # ---------------------------------------------------------------------------
  # Frontend - Nginx serving Vue.js SPA (Development)
  # ---------------------------------------------------------------------------
  frontend:
    build:
      context: ../vuejs
      dockerfile: Dockerfile
    container_name: aynux-frontend
    restart: unless-stopped
    ports:
      - "3002:80"
    depends_on:
      app:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:80/health"]
      interval: 30s
      timeout: 5s
      retries: 3
      start_period: 10s
    networks:
      - aynux-network

# =============================================================================
# Networks
# =============================================================================
networks:
  aynux-network:
    driver: bridge
    name: aynux-network

# =============================================================================
# Volumes (persistent data)
# =============================================================================
volumes:
  postgres_data:
    name: aynux-postgres-data
  redis_data:
    name: aynux-redis-data
  ollama_data:
    name: aynux-ollama-data
