"""
Agente de fallback para consultas no reconocidas
"""

import logging
from typing import Any, Dict, Optional

from ..integrations.ollama_integration import OllamaIntegration
from .base_agent import BaseAgent

logger = logging.getLogger(__name__)


class FallbackAgent(BaseAgent):
    """Agente para manejar consultas no reconocidas y guiar al usuario"""

    def __init__(self, ollama=None, postgres=None, config: Optional[Dict[str, Any]] = None):
        super().__init__("fallback_agent", config or {}, ollama=ollama, postgres=postgres)
        self.ollama = ollama or OllamaIntegration()

    async def _process_internal(self, message: str, state_dict: Dict[str, Any]) -> Dict[str, Any]:
        """
        Procesa mensajes no reconocidos y guÃ­a al usuario.

        Args:
            message: Mensaje del usuario
            state_dict: Estado actual como diccionario

        Returns:
            Diccionario con actualizaciones para el estado
        """
        try:
            # Generate helpful response
            response_text = await self._generate_helpful_response(message)

            return {
                "messages": [{"role": "assistant", "content": response_text}],
                "current_agent": self.name,
                "agent_history": [self.name],
                "is_complete": True,
            }

        except Exception as e:
            logger.error(f"Error in fallback agent: {str(e)}")

            error_response = """No entendÃ­ tu consulta, pero puedo ayudarte con:
â€¢ ğŸ›ï¸ Ver productos y categorÃ­as
â€¢ ğŸ’» Buscar equipos especÃ­ficos
â€¢ ğŸ“¦ Seguimiento de pedidos
â€¢ ğŸ¯ Ofertas y promociones
â€¢ ğŸ’¬ Soporte tÃ©cnico

Â¿Con quÃ© te gustarÃ­a empezar?"""

            return {
                "messages": [{"role": "assistant", "content": error_response}],
                "error_count": state_dict.get("error_count", 0) + 1,
                "current_agent": self.name,
            }

    async def _generate_helpful_response(self, message: str) -> str:
        """Generate a helpful response for unrecognized queries."""
        prompt = f"""
El usuario escribiÃ³: "{message}"

Parece que su consulta no fue clara o no es reconocida.

Responde de forma amable y Ãºtil:
â€¢ Sugiere 3 o 4 cosas comunes que podemos ayudar (ej: precios, soporte, pedidos).
â€¢ SÃ© breve (mÃ¡ximo 4 lÃ­neas).
â€¢ Usa emojis para hacerlo mÃ¡s cÃ¡lido.
â€¢ No repitas el mensaje del usuario.
"""

        try:
            llm = self.ollama.get_llm(temperature=0.7)
            response = await llm.ainvoke(prompt)
            return response.content  # type: ignore
        except Exception as e:
            logger.error(f"Error generating fallback response: {str(e)}")
            return self._get_default_response()

    def _get_default_response(self) -> str:
        """Get default fallback response."""
        return """No entendÃ­ tu consulta, pero estoy aquÃ­ para ayudarte ğŸ˜Š

Puedo asistirte con:
â€¢ ğŸ›’ Ver productos disponibles
â€¢ ğŸ’° Consultar precios y ofertas
â€¢ ğŸ“¦ Rastrear tu pedido
â€¢ ğŸ”§ Soporte tÃ©cnico

Â¿QuÃ© te gustarÃ­a hacer?"""

