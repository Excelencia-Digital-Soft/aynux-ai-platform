# =============================================================================
# AYNUX - Environment Configuration Template
# =============================================================================
# Copy this file to .env and configure your values:
#   cp .env.example .env
#
# Variables marked with (required) MUST be set before running the application.
# Variables marked with (optional) have sensible defaults for development.
#
# For Docker deployment, see: docs/DOCKER_DEPLOYMENT.md
# =============================================================================


# =============================================================================
# 1. APPLICATION CORE
# Core application settings that control runtime behavior
# =============================================================================

# Environment mode: development | production | test
ENVIRONMENT=development

# Enable debug mode with verbose logging (disable in production)
DEBUG=true

# Enable test mode for running test suites
TESTING=false

# Skip database initialization on startup (useful for Docker)
SKIP_DB_INIT=false

# Multi-Tenancy Configuration
MULTI_TENANT_MODE=true
TENANT_HEADER=X-Tenant-ID


# =============================================================================
# 2. API CONFIGURATION
# FastAPI application metadata and routing
# =============================================================================

# API URL for Streamlit
API_BASE_URL=http://localhost:8001

# API version prefix for all routes
API_V1_STR=/api/v1

# Application display name (shown in OpenAPI docs)
PROJECT_NAME=Aynux WhatsApp Bot

# Application description for API documentation
PROJECT_DESCRIPTION=Multi-domain WhatsApp bot with AI agents

# Application version
VERSION=1.0.0


# =============================================================================
# 3. WHATSAPP INTEGRATION
# WhatsApp Business API credentials and configuration
# =============================================================================

# Meta/Facebook Graph API base URL
WHATSAPP_API_BASE=https://graph.facebook.com

# WhatsApp Cloud API version
WHATSAPP_API_VERSION=v22.0

# (required) Your WhatsApp Business phone number ID
WHATSAPP_PHONE_NUMBER_ID=your_phone_number_id

# (required) Webhook verification token (you create this)
WHATSAPP_VERIFY_TOKEN=your_webhook_verify_token

# (required) Permanent access token from Meta Developer Portal
WHATSAPP_ACCESS_TOKEN=your_whatsapp_access_token

# (required) WhatsApp Business Catalog ID for product display
WHATSAPP_CATALOG_ID=your_catalog_id

# (required) Facebook/Meta application ID
META_APP_ID=your_meta_app_id

# (required) Facebook/Meta application secret
META_APP_SECRET=your_meta_app_secret


# =============================================================================
# 4. POSTGRESQL DATABASE
# Primary database connection settings
# =============================================================================

# Database hostname (use 'postgres' for Docker)
DB_HOST=localhost

# PostgreSQL port
DB_PORT=5432

# Database name
DB_NAME=aynux

# Database username
DB_USER=postgres

# Database password (leave empty for local dev without auth)
DB_PASSWORD=

# Log SQL queries for debugging (disable in production)
DB_ECHO=false


# =============================================================================
# 5. DATABASE POOL SETTINGS
# Connection pool configuration for production performance
# =============================================================================

# Number of persistent connections in the pool (1-100)
DB_POOL_SIZE=20

# Maximum overflow connections above pool size (0-200)
DB_MAX_OVERFLOW=30

# Recycle connections after this many seconds
DB_POOL_RECYCLE=3600

# Timeout waiting for a connection from pool (seconds)
DB_POOL_TIMEOUT=30


# =============================================================================
# 6. REDIS CACHE
# Redis server for caching, sessions, and rate limiting
# =============================================================================

# Redis hostname (use 'redis' for Docker)
REDIS_HOST=localhost

# Redis port
REDIS_PORT=6379

# Redis database number (0-15)
REDIS_DB=0

# Redis password (leave empty for local dev without auth)
REDIS_PASSWORD=


# =============================================================================
# 7. OLLAMA AI/LLM
# Local LLM service configuration for AI inference
# =============================================================================

# Ollama API URL (use http://host.docker.internal:11434 for Docker on Mac)
# Para desarrollo local usa: http://localhost:11434
# Para Docker usa: http://host.docker.internal:11434
OLLAMA_API_URL=http://host.docker.internal:11434

# =============================================================================
# MODEL TIERS - 4-tier model system for different complexity levels
# =============================================================================

# SIMPLE: Fast model for intent analysis and classification
OLLAMA_API_MODEL_SIMPLE=deepseek-r1:1.5b

# COMPLEX: Powerful model for complex responses and reasoning
OLLAMA_API_MODEL_COMPLEX=deepseek-r1:7b

# REASONING: Deep reasoning model for complex analysis (can be same as COMPLEX)
OLLAMA_API_MODEL_REASONING=deepseek-r1:7b

# SUMMARY: Fast non-reasoning model for conversation summarization
# IMPORTANT: Use a FAST non-reasoning model here.
# DeepSeek-R1 models generate internal "thinking tokens" before responding,
# which multiplies response time 10-50x (causing 3-10 minute delays).
# Recommended: llama3.2:3b (fast, good quality), qwen3:4b, llama3.1:8b
# NOT recommended: deepseek-r1:*, or any "thinking"/"reasoning" models
OLLAMA_API_MODEL_SUMMARY=llama3.2:latest

# Embedding model for vector similarity search (768 dimensions)
OLLAMA_API_MODEL_EMBEDDING=nomic-embed-text


# =============================================================================
# 8. VECTOR SEARCH (pgvector)
# PostgreSQL native vector similarity search configuration
# =============================================================================

# Enable pgvector for semantic search (recommended)
USE_PGVECTOR=true

# Minimum similarity threshold for search results (0.0-1.0, higher = stricter)
PGVECTOR_SIMILARITY_THRESHOLD=0.7


# =============================================================================
# 9. KNOWLEDGE BASE (RAG)
# Retrieval-Augmented Generation configuration
# =============================================================================

# Enable RAG knowledge base for domain-specific information
KNOWLEDGE_BASE_ENABLED=true

# Embedding model for knowledge base (should match OLLAMA_API_MODEL_EMBEDDING)
KNOWLEDGE_EMBEDDING_MODEL=nomic-embed-text

# Similarity threshold for knowledge retrieval (0.0-1.0)
KNOWLEDGE_SIMILARITY_THRESHOLD=0.7


# =============================================================================
# 10. DUX ERP INTEGRATION
# External ERP system connection for product data
# =============================================================================

# DUX API base URL
DUX_API_BASE_URL=https://erp.duxsoftware.com.ar/WSERP/rest/services

# (required for DUX) API authentication key
DUX_API_KEY=your_dux_api_key

# Request timeout in seconds
DUX_API_TIMEOUT=30

# Minimum seconds between API requests (rate limiting)
DUX_API_RATE_LIMIT_SECONDS=5

# Batch size for product synchronization
DUX_SYNC_BATCH_SIZE=50


# =============================================================================
# 11. DUX SYNCHRONIZATION
# Master toggle for DUX ERP integration (sync + ProductAgent)
# =============================================================================

# Master toggle for DUX integration
# When disabled (false):
#   - Background sync service does NOT start
#   - ProductAgent is automatically disabled from agent flow
# When enabled (true):
#   - Background sync runs at configured hours (DUX_SYNC_HOURS)
#   - ProductAgent is available for product queries
DUX_SYNC_ENABLED=false

# Hours to run automatic sync (24-hour format, JSON array)
# Example: [2, 14] means 2:00 AM and 2:00 PM
DUX_SYNC_HOURS=[2, 14]

# Force sync if data is older than this many hours
DUX_FORCE_SYNC_THRESHOLD_HOURS=24


# =============================================================================
# 11b. PHARMACY ERP INTEGRATION
# External Pharmacy ERP system for debt and invoice management
# =============================================================================

# Pharmacy ERP API base URL
# Example: https://pharmacy-erp.example.com/api
PHARMACY_ERP_BASE_URL=

# (required for Pharmacy) Bearer token for authentication
PHARMACY_API_TOKEN=

# Request timeout in seconds
PHARMACY_ERP_TIMEOUT=30


# =============================================================================
# 12. AGENT CONFIGURATION
# LangGraph multi-agent system settings
# =============================================================================

# JSON array of enabled agents
# Available:
#   - greeting_agent: Handles greetings and system capabilities
#   - ecommerce_agent: NEW! Consolidated e-commerce agent with subgraph
#                      (handles products, promotions, tracking, billing internally)
#   - data_insights_agent: Analytics and reporting
#   - support_agent: Technical support
#   - excelencia_agent: Excelencia ERP queries
#   - pharmacy_operations_agent: Pharmacy debt and invoice workflows
#   - fallback_agent: Default responses
#   - farewell_agent: Conversation closure
#
# Legacy agents (deprecated, use ecommerce_agent instead):
#   - product_agent, promotions_agent, tracking_agent, invoice_agent
#
# Note: ecommerce_agent replaces individual e-commerce agents
# Note: pharmacy_operations_agent requires PHARMACY_ERP_BASE_URL configuration
ENABLED_AGENTS=["greeting_agent","ecommerce_agent","data_insights_agent","support_agent","excelencia_agent","fallback_agent","farewell_agent"]

# Data source for product agent (always 'database' with pgvector)
PRODUCT_AGENT_DATA_SOURCE=database


# =============================================================================
# 13. JWT AUTHENTICATION
# JSON Web Token configuration for API authentication
# =============================================================================

# (required) Secret key for JWT signing (min 32 characters, use a secure random value)
# Generate with: python -c "import secrets; print(secrets.token_urlsafe(32))"
JWT_SECRET_KEY=generate_a_secure_random_key_at_least_32_characters

# Access token expiration in minutes (1440 = 24 hours)
ACCESS_TOKEN_EXPIRE_MINUTES=1440

# Refresh token expiration in days
REFRESH_TOKEN_EXPIRE_DAYS=7


# =============================================================================
# 14. FILE UPLOAD
# File upload limits and allowed types
# =============================================================================

# Maximum file size in bytes (10485760 = 10MB)
MAX_FILE_SIZE=10485760

# Allowed file extensions (JSON array format)
ALLOWED_EXTENSIONS=["jpg","jpeg","png","pdf","doc","docx"]


# =============================================================================
# 15. LANGSMITH MONITORING
# LangChain observability and tracing platform
# =============================================================================

# Enable LangSmith tracing (legacy variable name)
LANGSMITH_TRACING=false

# Enable LangSmith tracing (preferred variable name)
LANGSMITH_TRACING_ENABLED=false

# LangSmith API endpoint
LANGSMITH_ENDPOINT=https://api.smith.langchain.com

# (required if tracing enabled) LangSmith API key
LANGSMITH_API_KEY=lsv2_your_langsmith_api_key

# LangSmith project name for trace organization
LANGSMITH_PROJECT=aynux-development

# Enable verbose logging for LangSmith
LANGSMITH_VERBOSE=false

# Trace sampling rate (0.0-1.0, 1.0 = trace all requests)
LANGSMITH_SAMPLE_RATE=1.0

# Enable automatic evaluation of traces
LANGSMITH_AUTO_EVAL=false

# Enable metrics collection
LANGSMITH_METRICS_ENABLED=true

# Dataset name for evaluations
LANGSMITH_DATASET_NAME=aynux-evals


# =============================================================================
# 16. SENTRY ERROR TRACKING
# Error monitoring and performance tracking
# =============================================================================

# Sentry DSN (Data Source Name) for error reporting
# Leave empty to disable Sentry
SENTRY_DSN=


# =============================================================================
# 17. LANGGRAPH ADVANCED
# Advanced LangGraph configuration for conversation management
# =============================================================================

# Enable PostgreSQL checkpointing for conversation persistence
USE_CHECKPOINTING=true

# PostgreSQL connection pool size for LangGraph
POSTGRES_POOL_SIZE=5

# Redis TTL for cached data in seconds (86400 = 24 hours)
REDIS_TTL=86400

# Maximum messages per rate limit window
RATE_LIMIT_MESSAGES=20

# Rate limit window in seconds
RATE_LIMIT_WINDOW=60

# Maximum message length allowed
MAX_MESSAGE_LENGTH=1000


# =============================================================================
# 18. FEATURE FLAGS
# Toggle experimental features (for gradual rollouts)
# =============================================================================

# Enable refactored intent analyzer (Phase 2)
USE_REFACTORED_INTENT_ANALYZER=false

# Enable refactored search strategies (Phase 3)
USE_REFACTORED_SEARCH_STRATEGIES=false
