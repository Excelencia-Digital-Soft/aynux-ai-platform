# =============================================================================
# AYNUX - Environment Configuration Template
# =============================================================================
# Copy this file to .env and configure your values:
#   cp .env.example .env
#
# Variables marked with (required) MUST be set before running the application.
# Variables marked with (optional) have sensible defaults for development.
#
# For Docker deployment, see: docs/DOCKER_DEPLOYMENT.md
# =============================================================================


# =============================================================================
# 1. APPLICATION CORE
# Core application settings that control runtime behavior
# =============================================================================

# Environment mode: development | production | test
ENVIRONMENT=development

# Enable debug mode with verbose logging (disable in production)
DEBUG=true

# Enable test mode for running test suites
TESTING=false

# Skip database initialization on startup (useful for Docker)
SKIP_DB_INIT=false

# Multi-Tenancy Configuration
MULTI_TENANT_MODE=true
TENANT_HEADER=X-Tenant-ID


# =============================================================================
# 2. API CONFIGURATION
# FastAPI application metadata and routing
# =============================================================================

# API version prefix for all routes
API_V1_STR=/api/v1

# Application display name (shown in OpenAPI docs)
PROJECT_NAME=Aynux WhatsApp Bot

# Application description for API documentation
PROJECT_DESCRIPTION=Multi-domain WhatsApp bot with AI agents

# Application version
VERSION=1.0.0


# =============================================================================
# 3. WHATSAPP INTEGRATION
# WhatsApp Business API credentials and configuration
# =============================================================================

# Meta/Facebook Graph API base URL
WHATSAPP_API_BASE=https://graph.facebook.com

# WhatsApp Cloud API version
WHATSAPP_API_VERSION=v22.0

# (required) Your WhatsApp Business phone number ID
WHATSAPP_PHONE_NUMBER_ID=your_phone_number_id

# (required) Webhook verification token (you create this)
WHATSAPP_VERIFY_TOKEN=your_webhook_verify_token

# (required) Permanent access token from Meta Developer Portal
WHATSAPP_ACCESS_TOKEN=your_whatsapp_access_token

# (required) WhatsApp Business Catalog ID for product display
WHATSAPP_CATALOG_ID=your_catalog_id

# (required) Facebook/Meta application ID
META_APP_ID=your_meta_app_id

# (required) Facebook/Meta application secret
META_APP_SECRET=your_meta_app_secret


# =============================================================================
# 4. POSTGRESQL DATABASE
# Primary database connection settings
# =============================================================================

# Database hostname (use 'postgres' for Docker)
DB_HOST=localhost

# PostgreSQL port
DB_PORT=5432

# Database name
DB_NAME=aynux

# Database username
DB_USER=postgres

# Database password (leave empty for local dev without auth)
DB_PASSWORD=

# Log SQL queries for debugging (disable in production)
DB_ECHO=false


# =============================================================================
# 5. DATABASE POOL SETTINGS
# Connection pool configuration for production performance
# =============================================================================

# Number of persistent connections in the pool (1-100)
DB_POOL_SIZE=20

# Maximum overflow connections above pool size (0-200)
DB_MAX_OVERFLOW=30

# Recycle connections after this many seconds
DB_POOL_RECYCLE=3600

# Timeout waiting for a connection from pool (seconds)
DB_POOL_TIMEOUT=30


# =============================================================================
# 6. REDIS CACHE
# Redis server for caching, sessions, and rate limiting
# =============================================================================

# Redis hostname (use 'redis' for Docker)
REDIS_HOST=localhost

# Redis port
REDIS_PORT=6379

# Redis database number (0-15)
REDIS_DB=0

# Redis password (leave empty for local dev without auth)
REDIS_PASSWORD=


# =============================================================================
# 7. OLLAMA AI/LLM
# Local LLM service configuration for AI inference
# =============================================================================

# Ollama API URL
# Para desarrollo local o SSH tunnel: http://localhost:11434
# Para Docker en Mac/Windows: http://host.docker.internal:11434
OLLAMA_API_URL=http://localhost:11434

# =============================================================================
# MODEL TIERS - 4-tier model system for different complexity levels
# =============================================================================

# SIMPLE: Fast model for intent analysis and classification
OLLAMA_API_MODEL_SIMPLE=llama3.2:latest

# COMPLEX: Powerful model for complex responses
OLLAMA_API_MODEL_COMPLEX=gemma2:latest

# REASONING: Deep reasoning model for complex analysis (can be same as COMPLEX)
OLLAMA_API_MODEL_REASONING=deepseek-r1:8b

# SUMMARY: Fast non-reasoning model for conversation summarization
# IMPORTANT: Use a FAST non-reasoning model here.
# DeepSeek-R1 models generate internal "thinking tokens" before responding,
# which multiplies response time 10-50x (causing 3-10 minute delays).
# Recommended: llama3.2:3b (fast, good quality), qwen3:4b, llama3.1:8b
# NOT recommended: deepseek-r1:*, or any "thinking"/"reasoning" models
OLLAMA_API_MODEL_SUMMARY=llama3.2:1b

# Embedding model for vector similarity search (768 dimensions)
OLLAMA_API_MODEL_EMBEDDING=nomic-embed-text

# =============================================================================
# OLLAMA PERFORMANCE SETTINGS
# =============================================================================

# Time model stays loaded in memory after request (e.g., 30m, 1h, 0 for immediate unload)
OLLAMA_KEEP_ALIVE=30m

# Number of threads for inference (adjust based on CPU cores)
OLLAMA_NUM_THREAD=8

# Pre-load LLM models on application startup (reduces first request latency)
OLLAMA_WARMUP_ON_STARTUP=true

# Timeout for LLM requests in seconds
OLLAMA_REQUEST_TIMEOUT=60

# =============================================================================
# LLM STREAMING CONFIGURATION
# =============================================================================

# Enable streaming for web responses (WebSocket/SSE)
LLM_STREAMING_ENABLED=false

# Enable streaming for webhook responses (usually false for WhatsApp)
LLM_STREAMING_FOR_WEBHOOK=false


# =============================================================================
# 7b. EXTERNAL LLM (DeepSeek, KIMI, OpenAI-compatible)
# Optional: Use external API for COMPLEX/REASONING tiers
# When enabled, SIMPLE/SUMMARY tiers still use Ollama local
# =============================================================================

# Enable external API for COMPLEX/REASONING tiers
EXTERNAL_LLM_ENABLED=false

# External LLM provider: deepseek, kimi, openai
EXTERNAL_LLM_PROVIDER=deepseek

# (required if enabled) API key for external provider
EXTERNAL_LLM_API_KEY=

# Base URL override (auto-detected for known providers if not set)
# DeepSeek: https://api.deepseek.com/v1
# KIMI: https://api.moonshot.ai/v1
# OpenAI: https://api.openai.com/v1
EXTERNAL_LLM_BASE_URL=

# Model for COMPLEX tier on external API
EXTERNAL_LLM_MODEL_COMPLEX=deepseek-chat

# Model for REASONING tier on external API
EXTERNAL_LLM_MODEL_REASONING=deepseek-reasoner

# Timeout for external API calls in seconds
EXTERNAL_LLM_TIMEOUT=120

# Max retries for external API calls
EXTERNAL_LLM_MAX_RETRIES=3

# Ollama model to use as fallback when external API fails
EXTERNAL_LLM_FALLBACK_MODEL=llama3.1:8b


# =============================================================================
# 8. VECTOR SEARCH (pgvector)
# PostgreSQL native vector similarity search configuration
# Note: pgvector is always enabled (no toggle)
# =============================================================================

# Minimum similarity threshold for search results (0.0-1.0, higher = stricter)
# Used for both product search and knowledge base
PGVECTOR_SIMILARITY_THRESHOLD=0.7


# =============================================================================
# 9. KNOWLEDGE BASE (RAG)
# Retrieval-Augmented Generation configuration
# =============================================================================

# Enable RAG knowledge base for domain-specific information
KNOWLEDGE_BASE_ENABLED=true

# Note: Knowledge base uses OLLAMA_API_MODEL_EMBEDDING for embeddings
# and PGVECTOR_SIMILARITY_THRESHOLD for similarity matching


# =============================================================================
# 10. DUX ERP INTEGRATION
# External ERP system connection for product data
# =============================================================================

# DUX API base URL
DUX_API_BASE_URL=https://erp.duxsoftware.com.ar/WSERP/rest/services

# (required for DUX) API authentication key
DUX_API_KEY=your_dux_api_key

# Request timeout in seconds
DUX_API_TIMEOUT=30

# Minimum seconds between API requests (rate limiting)
DUX_API_RATE_LIMIT_SECONDS=5

# Batch size for product synchronization
DUX_SYNC_BATCH_SIZE=50


# =============================================================================
# 11. DUX SYNCHRONIZATION
# Master toggle for DUX ERP integration (sync + ProductAgent)
# =============================================================================

# Master toggle for DUX integration
# When disabled (false):
#   - Background sync service does NOT start
#   - ProductAgent is automatically disabled from agent flow
# When enabled (true):
#   - Background sync runs at configured hours (DUX_SYNC_HOURS)
#   - ProductAgent is available for product queries
DUX_SYNC_ENABLED=false

# Hours to run automatic sync (24-hour format, JSON array)
# Example: [2, 14] means 2:00 AM and 2:00 PM
DUX_SYNC_HOURS=[2, 14]

# Force sync if data is older than this many hours
DUX_FORCE_SYNC_THRESHOLD_HOURS=24


# =============================================================================
# 11b. PLEX ERP INTEGRATION (Pharmacy)
# Plex ERP system for pharmacy debt and invoice management
# Connection: Local network, requires VPN access
# Auth: HTTP Basic Authentication
# =============================================================================

# Plex ERP API base URL (local network address)
PLEX_API_BASE_URL=http://192.168.100.10:8081/wsplex

# HTTP Basic Auth username for Plex API
PLEX_API_USER=your_plex_username

# HTTP Basic Auth password for Plex API
PLEX_API_PASS=your_plex_password

# Request timeout in seconds
PLEX_API_TIMEOUT=30


# =============================================================================
# 11c. PAYMENT RECEIPT STORAGE
# PDF receipt storage settings (MP and pharmacy config now in database)
# =============================================================================

# Directory path for storing PDF receipts
RECEIPT_STORAGE_PATH=app/static/receipts

# Number of days to keep receipts before cleanup
RECEIPT_CLEANUP_DAYS=30

# NOTE: Mercado Pago credentials and pharmacy info are now stored per-organization
# in the database (pharmacy_merchant_configs table). Configure via admin UI or
# direct database insert. See: PharmacyMerchantConfig model and PharmacyConfigService


# =============================================================================
# 11d. WHATSAPP TEMPLATE SETTINGS
# WhatsApp template message configuration for payment receipts
# =============================================================================

# Template name for payment receipts (must be pre-approved in Meta Business)
WA_PAYMENT_RECEIPT_TEMPLATE=payment_receipt

# Language code for the template
WA_PAYMENT_RECEIPT_LANGUAGE=es


# =============================================================================
# 12. AGENT CONFIGURATION
# LangGraph multi-agent system settings
# =============================================================================

# JSON array of enabled agents
# Available:
#   - greeting_agent: Handles greetings and system capabilities
#   - ecommerce_agent: NEW! Consolidated e-commerce agent with subgraph
#                      (handles products, promotions, tracking, billing internally)
#   - data_insights_agent: Analytics and reporting
#   - support_agent: Technical support
#   - excelencia_agent: Excelencia Software queries
#   - pharmacy_operations_agent: Pharmacy debt and invoice workflows
#   - fallback_agent: Default responses
#   - farewell_agent: Conversation closure
#
# Legacy agents (deprecated, use ecommerce_agent instead):
#   - product_agent, promotions_agent, tracking_agent, invoice_agent
#
# Note: ecommerce_agent replaces individual e-commerce agents
# Note: pharmacy_operations_agent requires PHARMACY_ERP_BASE_URL configuration
ENABLED_AGENTS=["greeting_agent","ecommerce_agent","data_insights_agent","support_agent","excelencia_agent","fallback_agent","farewell_agent"]

# Data source for product agent (always 'database' with pgvector)
PRODUCT_AGENT_DATA_SOURCE=database


# =============================================================================
# 13. JWT AUTHENTICATION
# JSON Web Token configuration for API authentication
# =============================================================================

# (required) Secret key for JWT signing (min 32 characters, use a secure random value)
# Generate with: python -c "import secrets; print(secrets.token_urlsafe(32))"
JWT_SECRET_KEY=generate_a_secure_random_key_at_least_32_characters

# Access token expiration in minutes (1440 = 24 hours)
ACCESS_TOKEN_EXPIRE_MINUTES=1440

# Refresh token expiration in days
REFRESH_TOKEN_EXPIRE_DAYS=7


# =============================================================================
# 14. FILE UPLOAD
# File upload limits and allowed types
# =============================================================================

# Maximum file size in bytes (10485760 = 10MB)
MAX_FILE_SIZE=10485760

# Allowed file extensions (JSON array format)
ALLOWED_EXTENSIONS=["jpg","jpeg","png","pdf","doc","docx"]


# =============================================================================
# 15. LANGSMITH MONITORING
# LangChain observability and tracing platform
# =============================================================================

# Enable LangSmith tracing
LANGSMITH_TRACING=false

# LangSmith API endpoint
LANGSMITH_ENDPOINT=https://api.smith.langchain.com

# (required if tracing enabled) LangSmith API key
LANGSMITH_API_KEY=lsv2_your_langsmith_api_key

# LangSmith project name for trace organization
LANGSMITH_PROJECT=aynux-development

# Enable verbose logging for LangSmith
LANGSMITH_VERBOSE=false

# Trace sampling rate (0.0-1.0, 1.0 = trace all requests)
LANGSMITH_SAMPLE_RATE=1.0

# Enable automatic evaluation of traces
LANGSMITH_AUTO_EVAL=false

# Enable metrics collection
LANGSMITH_METRICS_ENABLED=true

# Dataset name for evaluations
LANGSMITH_DATASET_NAME=aynux-evals


# =============================================================================
# 16. SENTRY ERROR TRACKING
# Error monitoring and performance tracking
# =============================================================================

# Sentry DSN (Data Source Name) for error reporting
# Leave empty to disable Sentry
SENTRY_DSN=


# =============================================================================
# END OF CONFIGURATION
# =============================================================================
